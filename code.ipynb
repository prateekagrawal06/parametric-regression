{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##all the import neccesary to carry out the computation\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from numpy.linalg import inv,solve,pinv\n",
    "from sklearn import linear_model\n",
    "from math import exp,fabs\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "## fucnction ot convert X nto Z matrix\n",
    "##take X and d-degree of polynomail as input and returns Z matrix\n",
    "def define_Z(X,d):\n",
    "    poly = PolynomialFeatures(d)\n",
    "    Z = poly.fit_transform(X)\n",
    "    return Z\n",
    "    \n",
    "    \n",
    "##function to train for polynomial function\n",
    "##input :- Z and Y labels \n",
    "##returns :- computed theta\n",
    "def single_poly_train(Z,Y):\n",
    "    \n",
    "    #print Z\n",
    "    pin = pinv(Z)\n",
    "    #print pin.shape\n",
    "    Q = np.dot(pin,Y)\n",
    "    return Q\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "## function to predict lables\n",
    "## takes new feature vector and theta as input an return preducted value of Y\n",
    "def single_poly_predict(Z,Q):\n",
    "    return np.transpose(np.dot(np.transpose(Q),np.transpose(Z)))\n",
    "    \n",
    "    \n",
    "    \n",
    "##function to train linear model \n",
    "##input :- feature vector and Label\n",
    "##returns :- value of theta\n",
    "def single_linear_train(X,Y):\n",
    "    m = len(Y)\n",
    "    \n",
    "    sum_x = sum(X[:,0])\n",
    "    \n",
    "    sum_x_2 = 0\n",
    "    for i in X[:,0]:\n",
    "        sum_x_2 += i**2\n",
    "    \n",
    "    sum_y = sum(Y[:,0])\n",
    "    \n",
    "    sum_x_y = 0\n",
    "    \n",
    "    for i in zip(X[:,0],Y[:,0]):\n",
    "        sum_x_y += i[0]*i[1]\n",
    "    \n",
    "    \n",
    "    A = np.array([[m,sum_x],[sum_x,sum_x_2]])\n",
    "    B = np.array([[sum_y],[sum_x_y]])\n",
    "\n",
    "    Q = solve(A, B)\n",
    "    return Q\n",
    "\n",
    "\n",
    "##Function to predict lables by linear model\n",
    "## input :- new features and theta\n",
    "##returns predicted value of Y\n",
    "def single_linear_predict(X,Q):\n",
    "    Y_hat = []\n",
    "    for i in range(len(X[:,0])):\n",
    "        Y_hat.append(Q[0,0] + X[i,0]*Q[1,0])\n",
    "    return np.array(Y_hat)\n",
    "    \n",
    "##function to compute mean square error\n",
    "def training_error(Y_hat,Y):\n",
    "    return np.mean((Y_hat - Y) ** 2)\n",
    "    \n",
    "        \n",
    "#function to compute testing error using ten croos fold for single variable data set\n",
    "def ten_cross_fold(X,Y):\n",
    "    accuracies = []\n",
    "    cv = KFold(len(Y),10)\n",
    "    for train_id,test_id in cv:\n",
    "        \n",
    "        Q = single_linear_train(X[train_id],Y[train_id])\n",
    "        \n",
    "        Y_hat = single_linear_predict(X[test_id],Q)\n",
    "        \n",
    "        \n",
    "        error = training_error(Y_hat,Y[test_id])\n",
    "        \n",
    "        accuracies.append(error)\n",
    "    \n",
    "    return np.mean(accuracies)\n",
    "\n",
    "#function to compute testing error using ten croos fold for multiple variable data set\n",
    "def ten_cross_fold_poly(Z,Y):\n",
    "    accuracies = []\n",
    "    cv = KFold(len(Y),10)\n",
    "    for train_id,test_id in cv:\n",
    "        \n",
    "        Q = single_poly_train(Z[train_id],Y[train_id])\n",
    "        \n",
    "        Y_hat = single_poly_predict(Z[test_id],Q)\n",
    "        \n",
    "        \n",
    "        error = training_error(Y_hat,Y[test_id])\n",
    "        \n",
    "        accuracies.append(error)\n",
    "    \n",
    "    return np.mean(accuracies)    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##single feature and linear model\n",
    "##calls all the apropriete function to get the training and testing error\n",
    "def single_linear_model(X,Y):\n",
    "    \n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    \n",
    "    Q = single_linear_train(X,Y)            ##trains and computes theta\n",
    "    Y_hat = single_linear_predict(X,Q)      ##predicts Y_hat\n",
    "    train_error.append(training_error(Y_hat,Y))\n",
    "    #print train_error\n",
    "    test_error.append(ten_cross_fold(X,Y))\n",
    "    #print test_error\n",
    "    return (train_error,test_error,Y_hat)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##single feature and non linear model\n",
    "##calls all the apropriete function to get the training and testing error\n",
    "def single_ploy_model(X,Y):\n",
    "    \n",
    "    train_error = []\n",
    "    test_error = []\n",
    "\n",
    "    for i in range(2,16):\n",
    "\n",
    "        Z = define_Z(X,i)\n",
    "        #print Z.shape\n",
    "        Q = single_poly_train(Z,Y)\n",
    "        #print Q.shape\n",
    "        Y_hat = single_poly_predict(Z,Q)\n",
    "        #print Y_hat.shape\n",
    "        #print Y.shape\n",
    "        train_error.append(training_error(Y_hat,Y))\n",
    "        \n",
    "        test_error.append(ten_cross_fold_poly(Z,Y))\n",
    "    return (train_error,test_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## iterative solution to predict theta using the learning rate and \n",
    "##then use it to predict Y and compute the testing error\n",
    "\n",
    "##Input :- feature vector, Y, threshold, learning rate and degree of the polynomial of define Z\n",
    "\n",
    "\n",
    "def iterative_solution(X,Y,thres,lr,d):    \n",
    "    best = False\n",
    "    Z = define_Z(X,d)\n",
    "    theta = np.zeros(shape=(Z.shape[1],1))\n",
    "    theta.fill(0.5)\n",
    "    max_it = 0\n",
    "    \n",
    "    \n",
    "    while best==False:\n",
    "        theta_pre = theta\n",
    "        grad = 2 * np.dot(Z.transpose(),(np.dot(Z,theta_pre) - Y))\n",
    "        theta =  theta_pre - (lr*grad)\n",
    "        J_theta_pre = np.dot(np.transpose(np.dot(Z,theta_pre) - Y),(np.dot(Z,theta_pre)-Y))\n",
    "        J_theta = np.dot(np.transpose(np.dot(Z,theta) - Y),(np.dot(Z,theta)-Y))\n",
    "        max_it += 1\n",
    "        #print J_theta\n",
    "        \n",
    "        if fabs((J_theta[0] - J_theta_pre[0])[0]) < thres or max_it == 100: ##condition to check to stop the while loop\n",
    "            best = True\n",
    "            #print theta\n",
    "    print \"ERROR:\", np.mean((np.dot(Z,theta) - Y)**2) ##error from the iteration method\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##main function to do all the functinality of the single feature\n",
    "##Take feature and Y as input\n",
    "\n",
    "def single_feature(X,Y):\n",
    "    if (len(X[1]) == 1 ):\n",
    "        plt.plot(X,Y,'ro')               ##plotting the data to gain some idea of the complexity\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.title(\"svar-set3\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        ##fitting my linear model and computing traning and testing error\n",
    "        train_linear,test_linear,Y_hat = single_linear_model(X,Y)\n",
    "        #print len(Y_hat)\n",
    "        #print len(Y)\n",
    "\n",
    "\n",
    "\n",
    "        ##plotting tthe model fitted by me\n",
    "        plt.plot(X,Y,'ro',X,Y_hat,lw = 4)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.title(\"Model fit by me for svar-set3\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print \"training error by me for linear regression:\",train_linear\n",
    "        print \"testing error by me for linear regression:\",test_linear\n",
    "\n",
    "        ##fitting the ready made python function for linear regression\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X, Y)\n",
    "        train_linear_python = np.mean(((regr.predict(X) - Y)/(Y)) ** 2)\n",
    "\n",
    "\n",
    "        ##using ten cross fold validation to get the testing error for ready made linear regression model\n",
    "        accuracies = []\n",
    "        cv = KFold(len(Y),10)\n",
    "\n",
    "        for train_id,test_id in cv:    \n",
    "            regr.fit(X[train_id],Y[train_id])\n",
    "            error = np.mean(((regr.predict(X[test_id]) - Y[test_id])/(Y[test_id])) ** 2)\n",
    "            accuracies.append(error)\n",
    "        test_linear_python = np.mean(accuracies)\n",
    "\n",
    "        ##plotting the model by scikit learn\n",
    "\n",
    "        plt.plot(X,Y,'ro',X,regr.predict(X),lw = 4)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.title(\"ready made linear regression for svar-set3\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print \"training error by readymade model for linear regression:%s \\n\" % train_linear_python\n",
    "        print \"testing error by readymade model for linear regression:%s \\n\" % test_linear_python\n",
    "       \n",
    "\n",
    "        train_poly,test_poly= single_ploy_model(X,Y)\n",
    "\n",
    "        print \"training error by me for  non linear regression(1,15): %s \\n\"  % train_poly\n",
    "        print \"testing error by me for non linear regression(1,15): %s \\n\" % test_poly\n",
    "        index = test_poly.index(min(test_poly)) + 2\n",
    "\n",
    "        #train = (a_train + b_train)\n",
    "        #test =  (a_test + b_test)\n",
    "        #print train\n",
    "        #print test\n",
    "\n",
    "        #plt.boxplot(train)\n",
    "        #plt.show()\n",
    "        \n",
    "        ##plotting the change in the training error with the polynomial\n",
    "        plt.plot(range(2,16),train_poly,'-bo')\n",
    "        plt.xlabel(\"degree\")\n",
    "        plt.ylabel(\"training error\")\n",
    "        plt.title(\"svar-set2\")\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        ##plotting the change in the testing error with the polynomial\n",
    "        plt.plot(range(2,16),test_poly,'-bo')\n",
    "        plt.xlabel(\"degree\")\n",
    "        plt.ylabel(\"test error\")\n",
    "        plt.title(\"svar-set1\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        Z = define_Z(X,index)\n",
    "        Q = single_poly_train(Z,Y)\n",
    "        Y_hat = single_poly_predict(Z,Q)\n",
    "\n",
    "\n",
    "        ##model fit with the polynomial degree with the least error\n",
    "        plt.plot(X,Y,'ro',X,Y_hat,'bo',lw = 2)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.title(\"Model fit by me for polynomial %d for svar-set1\" % index)\n",
    "        plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##function to carry out all the opeartion on the multi feature data set\n",
    "\n",
    "\n",
    "def multi_feature(X,Y):  \n",
    "    test_error = []\n",
    "    for i in range (1,4):  ## fitting the model of polynomail degree 1 to 3\n",
    "        Z = define_Z(X,i)\n",
    "        Q = single_poly_train(Z,Y)\n",
    "        #print Q\n",
    "        Y_hat = single_poly_predict(Z,Q)\n",
    "        test_error.append(ten_cross_fold_poly(Z,Y))\n",
    "    print test_error\n",
    "    min_error = test_error.index(min(test_error))+1\n",
    "    print \"minimum error with degree: \",min_error\n",
    "    \n",
    "    ## plotting the testing error to compare each degree and find the best degree \n",
    "    plt.plot(range(1,4),test_error,'-bo')\n",
    "    plt.xlabel(\"degree\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.title(\"Model fit by me for multifeature polynomial\")\n",
    "    plt.show() \n",
    "    return min_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##guassian function to compute the similarity between two vectors\n",
    "##input :- two vectors x and y, value of sigma\n",
    "\n",
    "def gaussian_similarity(X,Y,sigma = 3.0):\n",
    "    m = np.dot(np.transpose(X-Y),(X-Y))\n",
    "    return exp(m*(-1/(2*(sigma**2)))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## calculating the gram matrix for a given matrix X\n",
    "##input :- feature matrix X\n",
    "##returns the gram matrix\n",
    "\n",
    "def gram_matrix(X):\n",
    "    m = len(X)\n",
    "    gram = np.zeros(shape=(m,m))\n",
    "    for i in range(m):\n",
    "        x = X[i]\n",
    "        for j in range(m):        \n",
    "            y = X[j]\n",
    "            gram[i][j] += gaussian_kernel(x,y)\n",
    "    return gram\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to print the error produces by the kernel method\n",
    "## Takes feature vector and labels as input\n",
    "\n",
    "def kernel_solution(X,Y):\n",
    "    \n",
    "    gram = gram_matrix(X) ##computes the gram matrix\n",
    "    \n",
    "    alpha = np.dot(inv(gram),Y) ##computes the parameter alpha\n",
    "    \n",
    "    y_hat =  np.zeros(shape=(m,1)) ##initializes the predictor matrix\n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        x = X[i]\n",
    "        z = np.zeros(shape=(m,1))  ##Z matrix containing the similarity \n",
    "\n",
    "        for j in range(m):\n",
    "\n",
    "            z[j][0] += gaussian_similarity(X[j],x)\n",
    "            \n",
    "        y_hat[i][0] = np.dot(np.transpose(alpha),z)\n",
    "        \n",
    "    print \"Error by kermel method: \",np.mean((y_hat - Y) ** 2) ##prints the mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### FOR SYNTHETIC DATA SET####\n",
    "\n",
    "\n",
    "data = urllib2.urlopen(\"http://www.cs.iit.edu/~agam/cs584/data/regression/svar-set3.dat\")\n",
    "data = data.read()\n",
    "data = data.split('\\n')\n",
    "data = data[:len(data)-1]\n",
    "X = []\n",
    "Y=[]\n",
    "\n",
    "##clean the data set and prepare the feature vector\n",
    "for i in data[5:]:\n",
    "    i = i.split()\n",
    "    a = []\n",
    "    for j in i[:-1]:\n",
    "        a.append(float(j))\n",
    "    X.append(a)\n",
    "    Y.append(float(i[len(i)-1]))\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.reshape(np.array(Y),(len(Y),1))\n",
    "\n",
    "##condition to check if the dataset is single variate##\n",
    "\n",
    "if (len(X[1])==1):\n",
    "    single_feature(X,Y) ##call to single_feature function to carry out all the operation on single variate dataset\n",
    "    print \"------------------------AFTER REDUCING THE AMOUNT OF DATA-----------------------------\"\n",
    "    m=int(.10*(len(X))) ##redusing  the amount of data set\n",
    "    single_feature(X[0:m],Y[0:m])\n",
    "    \n",
    "##if the data set id multi variate##\n",
    "else:\n",
    "    ##time function to calculate the time take by the function\n",
    "    time_func = time.time\n",
    "    startTime = time_func()\n",
    "    min_error_at = multi_feature(X,Y) ##call to multi_feature function to carry out all the operation on multi variate dataset\n",
    "    endTime = time_func()\n",
    "    print min_error_at\n",
    "    print \"Time Taken:\",endTime-startTime\n",
    "    time_dim.append(endTime-startTime)\n",
    "    \n",
    "    print \"---------------------------WITH ITERATIVE SOLUTION----------------------------------\"\n",
    "    \n",
    "    ## to check the testing error for the iterative approach using gradient desent\n",
    "    time_func = time.time\n",
    "    startTime = time_func()\n",
    "    iterative_solution(X,Y,0.01,0.0000001,min_error_at) ##calling the function with different values of LR to find\n",
    "                                                        ##the optimal LR for a given data set\n",
    "    \n",
    "    endTime = time_func()\n",
    "    print \"Time Taken:\",endTime-startTime\n",
    "    \n",
    "    print \"----------------------------KERNEL SOLUTION-----------------------------------------\"\n",
    "    \n",
    "    time_func = time.time\n",
    "    startTime = time_func()\n",
    "    kernel_solution(X,Y) ## calling the kernel function \n",
    "    endTime = time_func()\n",
    "    print \"Time Taken:\",endTime-startTime\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###REAL DATA SET WITH 5 FEATURES AND ONE PREDICTED VALUE ###\n",
    "\n",
    "## same code as above but with different data set and cleaning method\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\"\n",
    "data = urllib2.urlopen(url)\n",
    "data = data.read()\n",
    "data = data.split('\\r')\n",
    "data = data[:-1]\n",
    "X = []\n",
    "Y=[]\n",
    "for i in data[:len(data)]:\n",
    "    i = i.split('\\t')\n",
    "    a = []\n",
    "    for j in i[:-1]:\n",
    "        a.append(float(j))\n",
    "    X.append(a)\n",
    "    Y.append(float(i[len(i)-1]))\n",
    "X = np.array(X)\n",
    "Y = np.reshape(np.array(Y),(len(Y),1))\n",
    "\n",
    "\n",
    "time_func = time.time\n",
    "startTime = time_func()\n",
    "min_error_at = multi_feature(X,Y)\n",
    "endTime = time_func()\n",
    "print min_error_at\n",
    "print \"Time Taken:\",endTime-startTime\n",
    "time_dim.append(endTime-startTime)\n",
    "    \n",
    "print \"---------------------------WITH ITERATIVE SOLUTION----------------------------------\"\n",
    "time_func = time.time\n",
    "startTime = time_func()\n",
    "iterative_solution(X,Y,0.01,0.000001,min_error_at)\n",
    "endTime = time_func()\n",
    "print \"Time Taken:\",endTime-startTime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
